{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0deec72e-3b9e-4aae-a62c-9161341fe5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "base_model = keras.applications.VGG16(\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37a31509-062f-4501-924f-043e0ce77721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "114dc065-7060-425a-8f23-a1b225482b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze base model\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0139a1a-af02-4e3b-b1d1-f0f8011a4ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create inputs with correct shape\n",
    "inputs = keras.Input(shape=(224, 224, 3))\n",
    "\n",
    "x = base_model(inputs, training=False)\n",
    "\n",
    "# Add pooling layer or flatten layer\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add final dense layer\n",
    "outputs = keras.layers.Dense(1, activation = 'softmax')(x)\n",
    "\n",
    "# Combine inputs and outputs to create model\n",
    "model = keras.Model(inputs,outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19990948-f4c8-4986-bead-243bd049da72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 14,715,201\n",
      "Trainable params: 513\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f558c642-1a48-44c0-9bc5-fb56ef295fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important to use binary crossentropy and binary accuracy as we now have a binary classification problem\n",
    "model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=True), metrics=[keras.metrics.BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae4cc924-e85d-4b1b-a5b4-728fb8072fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# create a data generator\n",
    "datagen = ImageDataGenerator(\n",
    "        samplewise_center=True,  # set each sample mean to 0\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False) # we don't expect Bo to be upside-down so we will not flip vertically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e641ade-e6ba-4f80-9061-0229cb35f1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2493 images belonging to 2 classes.\n",
      "Found 1599 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# load and iterate training dataset\n",
    "train_it = datagen.flow_from_directory('dataset/mask/train/', \n",
    "                                       target_size=(224, 224), \n",
    "                                       color_mode='rgb', \n",
    "                                       class_mode='binary', \n",
    "                                       batch_size=8)\n",
    "# load and iterate validation dataset\n",
    "valid_it = datagen.flow_from_directory('dataset/mask/valid/', \n",
    "                                      target_size=(224, 224), \n",
    "                                      color_mode='rgb', \n",
    "                                      class_mode='binary', \n",
    "                                      batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b6ac3d2-781c-4667-b823-78dbe367ce20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\x7amo\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\keras\\backend.py:4993: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 10s 139ms/step - loss: 0.8120 - binary_accuracy: 0.4479 - val_loss: 0.1492 - val_binary_accuracy: 0.6562\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 2s 127ms/step - loss: 0.5272 - binary_accuracy: 0.4271 - val_loss: 0.2636 - val_binary_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 2s 122ms/step - loss: 0.3487 - binary_accuracy: 0.3854 - val_loss: 0.0928 - val_binary_accuracy: 0.5312\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 2s 123ms/step - loss: 0.4805 - binary_accuracy: 0.4271 - val_loss: 0.2466 - val_binary_accuracy: 0.6250\n",
      "Epoch 5/20\n",
      " 8/12 [===================>..........] - ETA: 0s - loss: 0.5023 - binary_accuracy: 0.4219"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\x7amo\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 120ms/step - loss: 0.4512 - binary_accuracy: 0.4583 - val_loss: 0.0871 - val_binary_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 2s 133ms/step - loss: 0.4532 - binary_accuracy: 0.4896 - val_loss: 0.1219 - val_binary_accuracy: 0.4688\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 0.3126 - binary_accuracy: 0.4271 - val_loss: 0.1067 - val_binary_accuracy: 0.4062\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 2s 129ms/step - loss: 0.2494 - binary_accuracy: 0.4375 - val_loss: 0.1093 - val_binary_accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 2s 130ms/step - loss: 0.2836 - binary_accuracy: 0.3854 - val_loss: 0.0249 - val_binary_accuracy: 0.5625\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 2s 124ms/step - loss: 0.0920 - binary_accuracy: 0.4688 - val_loss: 0.0340 - val_binary_accuracy: 0.5625\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 2s 123ms/step - loss: 0.2499 - binary_accuracy: 0.3854 - val_loss: 0.0549 - val_binary_accuracy: 0.4688\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 2s 202ms/step - loss: 0.2262 - binary_accuracy: 0.4688 - val_loss: 0.1336 - val_binary_accuracy: 0.2188\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 2s 125ms/step - loss: 0.1590 - binary_accuracy: 0.5312 - val_loss: 0.0873 - val_binary_accuracy: 0.5312\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 2s 137ms/step - loss: 0.2667 - binary_accuracy: 0.4375 - val_loss: 0.0737 - val_binary_accuracy: 0.6250\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 2s 125ms/step - loss: 0.2102 - binary_accuracy: 0.5000 - val_loss: 0.0830 - val_binary_accuracy: 0.5938\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 2s 129ms/step - loss: 0.2907 - binary_accuracy: 0.3542 - val_loss: 0.0343 - val_binary_accuracy: 0.5000\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 2s 126ms/step - loss: 0.1163 - binary_accuracy: 0.5000 - val_loss: 0.0263 - val_binary_accuracy: 0.5625\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 0.1725 - binary_accuracy: 0.4375 - val_loss: 0.0959 - val_binary_accuracy: 0.6875\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 2s 141ms/step - loss: 0.0942 - binary_accuracy: 0.4167 - val_loss: 0.0694 - val_binary_accuracy: 0.5625\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 0.0845 - binary_accuracy: 0.4375 - val_loss: 0.0067 - val_binary_accuracy: 0.5625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c37f673c70>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.fit(train_it,\n",
    "#          validation_data=valid_it,\n",
    " #         steps_per_epoch=train_it.samples/train_it.batch_size,\n",
    "  #        validation_steps=valid_it.samples/valid_it.batch_size,\n",
    "   #       epochs=5)\n",
    "    \n",
    "model.fit(train_it, steps_per_epoch=12, validation_data=valid_it, validation_steps=4, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97bb08e1-1f7d-4298-8c15-4216c1f836c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the base model\n",
    "base_model.trainable = True\n",
    "\n",
    "# It's important to recompile your model after you make any changes\n",
    "# to the `trainable` attribute of any inner layer, so that your changes\n",
    "# are taken into account\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(learning_rate = .00001),  # Very low learning rate\n",
    "              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[keras.metrics.BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe86496d-c952-495c-ac54-19c51282fa06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "12/12 [==============================] - 44s 245ms/step - loss: 0.2855 - binary_accuracy: 0.5104 - val_loss: 0.0063 - val_binary_accuracy: 0.6562\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 3s 237ms/step - loss: 0.0560 - binary_accuracy: 0.4583 - val_loss: 0.3144 - val_binary_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 3s 234ms/step - loss: 0.0533 - binary_accuracy: 0.3958 - val_loss: 1.8847e-04 - val_binary_accuracy: 0.5625\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 3s 229ms/step - loss: 0.0851 - binary_accuracy: 0.4583 - val_loss: 0.0365 - val_binary_accuracy: 0.4375\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 3s 229ms/step - loss: 0.2610 - binary_accuracy: 0.4375 - val_loss: 0.0469 - val_binary_accuracy: 0.6875\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 3s 233ms/step - loss: 0.0739 - binary_accuracy: 0.4792 - val_loss: 8.8429e-04 - val_binary_accuracy: 0.7188\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 5s 390ms/step - loss: 0.0033 - binary_accuracy: 0.4583 - val_loss: 0.0587 - val_binary_accuracy: 0.4688\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 5s 417ms/step - loss: 0.0029 - binary_accuracy: 0.4688 - val_loss: 0.0035 - val_binary_accuracy: 0.6562\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 6s 541ms/step - loss: 0.2057 - binary_accuracy: 0.4375 - val_loss: 0.0181 - val_binary_accuracy: 0.5625\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 5s 434ms/step - loss: 0.0113 - binary_accuracy: 0.4479 - val_loss: 0.1406 - val_binary_accuracy: 0.6250\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 9s 617ms/step - loss: 0.0061 - binary_accuracy: 0.4792 - val_loss: 5.8092e-05 - val_binary_accuracy: 0.4375\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 6s 539ms/step - loss: 0.0273 - binary_accuracy: 0.5104 - val_loss: 0.0241 - val_binary_accuracy: 0.5625\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.0621 - binary_accuracy: 0.4271 - val_loss: 4.9112e-04 - val_binary_accuracy: 0.5000\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.0664 - binary_accuracy: 0.4062 - val_loss: 0.0039 - val_binary_accuracy: 0.5938\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 3s 266ms/step - loss: 5.9668e-04 - binary_accuracy: 0.4792 - val_loss: 1.1195e-04 - val_binary_accuracy: 0.5625\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 6s 526ms/step - loss: 0.1293 - binary_accuracy: 0.4375 - val_loss: 1.9016e-04 - val_binary_accuracy: 0.6250\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 4s 296ms/step - loss: 0.0298 - binary_accuracy: 0.3750 - val_loss: 6.4165e-04 - val_binary_accuracy: 0.4688\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 4s 291ms/step - loss: 0.1731 - binary_accuracy: 0.5000 - val_loss: 0.0030 - val_binary_accuracy: 0.3750\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0085 - binary_accuracy: 0.4062"
     ]
    }
   ],
   "source": [
    "#model.fit(train_it,\n",
    "#          validation_data=valid_it,\n",
    "#          steps_per_epoch=train_it.samples/train_it.batch_size,\n",
    "#         validation_steps=valid_it.samples/valid_it.batch_size,\n",
    "#        epochs=5)\n",
    "model.fit(train_it, steps_per_epoch=12, validation_data=valid_it, validation_steps=4, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a7646b-b88a-4e37-bfaa-90ffa69a0011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from tensorflow.keras.preprocessing import image as image_utils\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "def show_image(image_path):\n",
    "    image = mpimg.imread(image_path)\n",
    "    plt.imshow(image)\n",
    "\n",
    "def make_predictions(image_path):\n",
    "    show_image(image_path)\n",
    "    image = image_utils.load_img(image_path, target_size=(224,224))\n",
    "    image = image_utils.img_to_array(image)\n",
    "    image = image.reshape(1,224,224,3)\n",
    "    image = preprocess_input(image)\n",
    "    preds = model.predict(image)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834939e7-8cdd-4a88-bea7-dde59e01ee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_predictions('dataset/mask/valid/mask/mask_(511).jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b04a4fa-ae17-490d-9397-d141bd02ca4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_predictions('dataset/mask/valid/no_mask/no_mask_(1348).jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4560e70c-71ed-4f4d-b2a1-2fd079f63834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_no_mask(image_path):\n",
    "    preds = make_predictions(image_path)\n",
    "    if preds[0] < 0:\n",
    "        print(\"It's mask\")\n",
    "    else:\n",
    "        print(\"That's not mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc00fd01-afac-4d68-9947-15a0ef3c1d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_no_mask('dataset/mask/valid/no_mask/no_mask_(1328).jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4f04ae-4468-476c-bcd4-20352e1ee3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_no_mask('dataset/mask/valid/mask/mask_(604).jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aab48326-e877-4e20-b950-a3d2f6c80295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3bc7b2-44c0-41ad-a620-ef274ab20ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f7bac1-8f97-4df6-855a-d6e875f2a27a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fa2f0a-8bed-423f-abf2-1b467b90098f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
